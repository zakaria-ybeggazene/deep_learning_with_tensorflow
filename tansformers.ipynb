{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOidWOvDNKVsDH8tymwALhL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"my2vSn06wviy"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"code","source":["class TransformerEncoder(layers.Layer):\n","  def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","    super().__init__(**kwargs)\n","    self.embed_dim = embed_dim\n","    self.dense_dim = dense_dim\n","    self.num_heads = num_heads\n","    self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.dense_proj = keras.Sequential([layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),])\n","    self.layernorm_1 = layers.LayerNormalization()\n","    self.layernorm_2 = layers.LayerNormalization()\n","  def call(self, inputs, mask=None):\n","    if mask is not None:\n","      mask = mask[:, tf.newaxis, :]\n","    attention_output = self.attention(inputs, inputs, attention_mask=mask)\n","    proj_input = self.layernorm_1(inputs + attention_output)\n","    proj_output = self.dense_proj(proj_input)\n","    return self.layernorm_2(proj_input + proj_output)\n","  def get_config(self):\n","    config = super().get_config()\n","    config.update({\"embed_dim\": self.embed_dim,\n","                  \"num_heads\": self.num_heads,\n","                  \"dense_dim\": self.dense_dim,})\n","    return config"],"metadata":{"id":"fqrK2FLJxS90"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz\n","!rm -r aclImdb/train/unsup"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iF7mVbyRxYCQ","executionInfo":{"status":"ok","timestamp":1670426587387,"user_tz":-60,"elapsed":28748,"user":{"displayName":"Zakaria Ybeggazene","userId":"17723444071190952793"}},"outputId":"35c68b7f-ee36-4199-dee0-503ad41891e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 80.2M  100 80.2M    0     0  3765k      0  0:00:21  0:00:21 --:--:-- 6289k\n"]}]},{"cell_type":"code","source":["import os, pathlib, shutil, random"],"metadata":{"id":"Vj_p7_yIyht5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_dir = pathlib.Path(\"aclImdb\")\n","val_dir = base_dir / \"val\"\n","train_dir = base_dir / \"train\"\n","for category in (\"neg\", \"pos\"):\n","  os.makedirs(val_dir / category)\n","  files = os.listdir(train_dir / category)\n","  random.Random(1337).shuffle(files)\n","  num_val_samples = int(0.2 * len(files))\n","  val_files = files[-num_val_samples:]\n","  for fname in val_files:\n","    shutil.move(train_dir / category / fname, val_dir / category / fname)"],"metadata":{"id":"Wm4iyJ3wymCW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","train_ds = keras.utils.text_dataset_from_directory(\"aclImdb/train\", batch_size=batch_size)\n","val_ds = keras.utils.text_dataset_from_directory(\"aclImdb/val\", batch_size=batch_size)\n","test_ds = keras.utils.text_dataset_from_directory(\"aclImdb/test\", batch_size=batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0o0qLXly3xr","executionInfo":{"status":"ok","timestamp":1670426598129,"user_tz":-60,"elapsed":6606,"user":{"displayName":"Zakaria Ybeggazene","userId":"17723444071190952793"}},"outputId":"823822aa-2de8-4ccc-a9f9-36cb5cbfd952"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20000 files belonging to 2 classes.\n","Found 5000 files belonging to 2 classes.\n","Found 25000 files belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["text_vectorization = layers.TextVectorization(max_tokens=20000,output_mode=\"multi_hot\",)\n","text_only_train_ds = train_ds.map(lambda x, y: x)\n","text_vectorization.adapt(text_only_train_ds)"],"metadata":{"id":"lTAnMcRiy9Vv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_length = 600\n","max_tokens = 20000\n","text_vectorization = layers.TextVectorization(max_tokens=max_tokens, output_mode=\"int\", output_sequence_length=max_length,)\n","text_vectorization.adapt(text_only_train_ds)"],"metadata":{"id":"04QK6J3WzD7v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n","int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n","int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)"],"metadata":{"id":"Og2vigyW0MHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size = 20000\n","embed_dim = 256\n","num_heads = 2\n","dense_dim = 32\n","inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","x = layers.Embedding(vocab_size, embed_dim)(inputs)\n","x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n","x = layers.GlobalMaxPooling1D()(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)"],"metadata":{"id":"jSZCfPzj0SOQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","callbacks = [keras.callbacks.ModelCheckpoint(\"transformer_encoder.keras\", save_best_only=True)]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)\n","model = keras.models.load_model(\"transformer_encoder.keras\", custom_objects={\"TransformerEncoder\": TransformerEncoder})\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":937},"id":"S3a4hTvi0cXd","executionInfo":{"status":"error","timestamp":1670421959620,"user_tz":-60,"elapsed":474,"user":{"displayName":"Zakaria Ybeggazene","userId":"17723444071190952793"}},"outputId":"64e54594-0414-49c2-806b-f4c88296a8c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-0e05f4c79222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transformer_encoder.keras\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_train_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint_val_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transformer_encoder.keras\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"TransformerEncoder\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTransformerEncoder\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 893, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 2071, in trainable_variables\n        return self.trainable_weights\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2348, in trainable_weights\n        trainable_variables += trackable_obj.trainable_variables\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 2071, in trainable_variables\n        return self.trainable_weights\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1166, in trainable_weights\n        children_weights = self._gather_children_attribute('trainable_variables')\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 2938, in _gather_children_attribute\n        return list(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 2940, in <genexpr>\n        getattr(layer, attribute) for layer in nested_layers))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 2071, in trainable_variables\n        return self.trainable_weights\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2343, in trainable_weights\n        self._assert_weights_created()\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py\", line 472, in _assert_weights_created\n        super(functional.Functional, self)._assert_weights_created()  # pylint: disable=bad-super-call\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 3027, in _assert_weights_created\n        raise ValueError(f'Weights for model {self.name} have not yet been '\n\n    ValueError: Weights for model sequential_4 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.\n"]}]},{"cell_type":"markdown","source":["# Positional Embedding"],"metadata":{"id":"bGhVIbK90h1I"}},{"cell_type":"code","source":["class PositionalEmbedding(layers.Layer):\n","  def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n","    super().__init__(**kwargs)\n","    self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n","    self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=output_dim)\n","    self.sequence_length = sequence_length\n","    self.input_dim = input_dim\n","    self.output_dim = output_dim\n","  def call(self, inputs):\n","    length = tf.shape(inputs)[-1]\n","    positions = tf.range(start=0, limit=length, delta=1)\n","    embedded_tokens = self.token_embeddings(inputs)\n","    embedded_positions = self.position_embeddings(positions)\n","    return embedded_tokens + embedded_positions\n","  def compute_mask(self, inputs, mask=None):\n","    return tf.math.not_equal(inputs, 0)\n","  def get_config(self):\n","    config = super().get_config()\n","    config.update({\"output_dim\": self.output_dim,\"sequence_length\": self.sequence_length, \"input_dim\": self.input_dim,})\n","    return config"],"metadata":{"id":"XiPMPuLn3m1T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size = 20000\n","sequence_length = 600\n","embed_dim = 256\n","num_heads = 2\n","dense_dim = 32"],"metadata":{"id":"0aPsIGxe5aKt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n","x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n","x = layers.GlobalMaxPooling1D()(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"],"metadata":{"id":"iCCM9LdY5c3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["callbacks = [keras.callbacks.ModelCheckpoint(\"full_transformer_encoder.keras\", save_best_only=True)]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)\n","model = keras.models.load_model(\"full_transformer_encoder.keras\", custom_objects={\"TransformerEncoder\": TransformerEncoder,\n","                                                                                  \"PositionalEmbedding\": PositionalEmbedding})\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\""],"metadata":{"id":"p-DMcIp_5eei"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Seq2Seq"],"metadata":{"id":"XflMTU_I5h1Y"}},{"cell_type":"code","source":["!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n","!unzip -q spa-eng.zip\n","text_file = \"spa-eng/spa.txt\"\n","with open(text_file) as f:\n","  lines = f.read().split(\"\\n\")[:-1]\n","text_pairs = []\n","for line in lines:\n","  english, spanish = line.split(\"\\t\")\n","  spanish = \"[start] \" + spanish + \" [end]\"\n","  text_pairs.append((english, spanish))\n","import random\n","random.shuffle(text_pairs)\n","num_val_samples = int(0.15 * len(text_pairs))\n","num_train_samples = len(text_pairs) - 2 * num_val_samples\n","train_pairs = text_pairs[:num_train_samples]\n","val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n","test_pairs = text_pairs[num_train_samples + num_val_samples:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7pJHkEdkD0d0","executionInfo":{"status":"ok","timestamp":1670426624228,"user_tz":-60,"elapsed":2454,"user":{"displayName":"Zakaria Ybeggazene","userId":"17723444071190952793"}},"outputId":"555e1ce3-1926-413e-8eba-788355d7d7ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-07 15:23:41--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.200.128, 74.125.68.128, 142.250.4.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.200.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2638744 (2.5M) [application/zip]\n","Saving to: ‘spa-eng.zip’\n","\n","spa-eng.zip         100%[===================>]   2.52M  2.09MB/s    in 1.2s    \n","\n","2022-12-07 15:23:43 (2.09 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n","\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import string\n","import re\n","strip_chars = string.punctuation + \"¿\"\n","strip_chars = strip_chars.replace(\"[\", \"\")\n","strip_chars = strip_chars.replace(\"]\", \"\")"],"metadata":{"id":"5lgrZNLnKGpu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def custom_standardization(input_string):\n","  lowercase = tf.strings.lower(input_string)\n","  return tf.strings.regex_replace(lowercase, f\"[{re.escape(strip_chars)}]\", \"\")"],"metadata":{"id":"we1HKhF7KO1u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size = 15000\n","sequence_length = 20"],"metadata":{"id":"j_kboW-VKR4Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["source_vectorization = layers.TextVectorization(max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,)\n","target_vectorization = layers.TextVectorization(max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length + 1,standardize=custom_standardization,)\n","train_english_texts = [pair[0] for pair in train_pairs]\n","train_spanish_texts = [pair[1] for pair in train_pairs]\n","source_vectorization.adapt(train_english_texts)\n","target_vectorization.adapt(train_spanish_texts)"],"metadata":{"id":"oKqynYksKTco"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 64\n","def format_dataset(eng, spa):\n","  eng = source_vectorization(eng)\n","  spa = target_vectorization(spa)\n","  return ({\"english\": eng, \"spanish\": spa[:, :-1],}, spa[:, 1:])\n","def make_dataset(pairs):\n","  eng_texts, spa_texts = zip(*pairs)\n","  eng_texts = list(eng_texts)\n","  spa_texts = list(spa_texts)\n","  dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n","  dataset = dataset.batch(batch_size)\n","  dataset = dataset.map(format_dataset, num_parallel_calls=4)\n","  return dataset.shuffle(2048).prefetch(16).cache()"],"metadata":{"id":"i162LXNkKU0y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = make_dataset(train_pairs)\n","val_ds = make_dataset(val_pairs)"],"metadata":{"id":"zBeg6qqxKbQZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TransformerDecoder(layers.Layer):\n","  def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","    super().__init__(**kwargs)\n","    self.embed_dim = embed_dim\n","    self.dense_dim = dense_dim\n","    self.num_heads = num_heads\n","    self.attention_1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.attention_2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.dense_proj = keras.Sequential([layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),])\n","    self.layernorm_1 = layers.LayerNormalization()\n","    self.layernorm_2 = layers.LayerNormalization()\n","    self.layernorm_3 = layers.LayerNormalization()\n","    self.supports_masking = True\n","  def get_config(self):\n","    config = super().get_config()\n","    config.update({\"embed_dim\": self.embed_dim, \"num_heads\": self.num_heads, \"dense_dim\": self.dense_dim,})\n","    return config\n","  def get_causal_attention_mask(self, inputs):\n","    input_shape = tf.shape(inputs)\n","    batch_size, sequence_length = input_shape[0], input_shape[1]\n","    i = tf.range(sequence_length)[:, tf.newaxis]\n","    j = tf.range(sequence_length)\n","    mask = tf.cast(i >= j, dtype=\"int32\")\n","    mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n","    mult = tf.concat([tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], axis=0)\n","    return tf.tile(mask, mult)\n","  def call(self, inputs, encoder_outputs, mask=None):\n","    causal_mask = self.get_causal_attention_mask(inputs)\n","    if mask is not None:\n","      padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n","      padding_mask = tf.minimum(padding_mask, causal_mask)\n","    attention_output_1 = self.attention_1(query=inputs, value=inputs, key=inputs, attention_mask=causal_mask)\n","    attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n","    attention_output_2 = self.attention_2(query=attention_output_1, value=encoder_outputs, key=encoder_outputs,\n","                                          attention_mask=padding_mask,)\n","    attention_output_2 = self.layernorm_2(attention_output_1 + attention_output_2)\n","    proj_output = self.dense_proj(attention_output_2)\n","    return self.layernorm_3(attention_output_2 + proj_output)"],"metadata":{"id":"Dcmn0uXTKdhI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embed_dim = 256\n","dense_dim = 2048\n","num_heads = 8"],"metadata":{"id":"21GEzIXgKkrJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n","encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)"],"metadata":{"id":"fj2vjQTOKnnh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n","x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n","x = layers.Dropout(0.5)(x)\n","decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)"],"metadata":{"id":"S_JPYmymKwB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","transformer.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","transformer.fit(train_ds, epochs=30, validation_data=val_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eJ4dG9t1K82B","executionInfo":{"status":"ok","timestamp":1670430009497,"user_tz":-60,"elapsed":3369159,"user":{"displayName":"Zakaria Ybeggazene","userId":"17723444071190952793"}},"outputId":"9ce3bf39-5992-4a88-f74b-a9b641fffdbd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","1302/1302 [==============================] - 98s 69ms/step - loss: 1.6553 - accuracy: 0.4262 - val_loss: 1.2938 - val_accuracy: 0.5210\n","Epoch 2/30\n","1302/1302 [==============================] - 89s 68ms/step - loss: 1.3191 - accuracy: 0.5423 - val_loss: 1.1436 - val_accuracy: 0.5791\n","Epoch 3/30\n","1302/1302 [==============================] - 91s 70ms/step - loss: 1.1678 - accuracy: 0.5900 - val_loss: 1.0671 - val_accuracy: 0.6074\n","Epoch 4/30\n","1302/1302 [==============================] - 91s 70ms/step - loss: 1.0805 - accuracy: 0.6207 - val_loss: 1.0275 - val_accuracy: 0.6284\n","Epoch 5/30\n","1302/1302 [==============================] - 89s 68ms/step - loss: 1.0341 - accuracy: 0.6419 - val_loss: 1.0079 - val_accuracy: 0.6387\n","Epoch 6/30\n","1302/1302 [==============================] - 89s 68ms/step - loss: 1.0042 - accuracy: 0.6578 - val_loss: 0.9922 - val_accuracy: 0.6471\n","Epoch 7/30\n","1302/1302 [==============================] - 90s 69ms/step - loss: 0.9836 - accuracy: 0.6690 - val_loss: 0.9876 - val_accuracy: 0.6517\n","Epoch 8/30\n","1302/1302 [==============================] - 91s 70ms/step - loss: 0.9662 - accuracy: 0.6787 - val_loss: 0.9859 - val_accuracy: 0.6536\n","Epoch 9/30\n","1302/1302 [==============================] - 89s 68ms/step - loss: 0.9509 - accuracy: 0.6873 - val_loss: 0.9825 - val_accuracy: 0.6580\n","Epoch 10/30\n","1302/1302 [==============================] - 90s 69ms/step - loss: 0.9374 - accuracy: 0.6945 - val_loss: 0.9853 - val_accuracy: 0.6597\n","Epoch 11/30\n","1302/1302 [==============================] - 91s 70ms/step - loss: 0.9253 - accuracy: 0.7012 - val_loss: 0.9890 - val_accuracy: 0.6602\n","Epoch 12/30\n","1302/1302 [==============================] - 92s 71ms/step - loss: 0.9134 - accuracy: 0.7064 - val_loss: 0.9944 - val_accuracy: 0.6593\n","Epoch 13/30\n","1302/1302 [==============================] - 89s 69ms/step - loss: 0.9021 - accuracy: 0.7116 - val_loss: 0.9928 - val_accuracy: 0.6623\n","Epoch 14/30\n","1302/1302 [==============================] - 92s 70ms/step - loss: 0.8914 - accuracy: 0.7165 - val_loss: 0.9886 - val_accuracy: 0.6621\n","Epoch 15/30\n","1302/1302 [==============================] - 89s 69ms/step - loss: 0.8832 - accuracy: 0.7207 - val_loss: 0.9929 - val_accuracy: 0.6641\n","Epoch 16/30\n","1302/1302 [==============================] - 90s 69ms/step - loss: 0.8731 - accuracy: 0.7248 - val_loss: 1.0004 - val_accuracy: 0.6632\n","Epoch 17/30\n","1302/1302 [==============================] - 91s 70ms/step - loss: 0.8638 - accuracy: 0.7286 - val_loss: 1.0030 - val_accuracy: 0.6632\n","Epoch 18/30\n","1302/1302 [==============================] - 89s 68ms/step - loss: 0.8541 - accuracy: 0.7321 - val_loss: 1.0043 - val_accuracy: 0.6641\n","Epoch 19/30\n","1302/1302 [==============================] - 90s 69ms/step - loss: 0.8445 - accuracy: 0.7360 - val_loss: 1.0079 - val_accuracy: 0.6635\n","Epoch 20/30\n","1302/1302 [==============================] - 89s 68ms/step - loss: 0.8359 - accuracy: 0.7389 - val_loss: 1.0097 - val_accuracy: 0.6646\n","Epoch 21/30\n","1302/1302 [==============================] - 90s 69ms/step - loss: 0.8276 - accuracy: 0.7417 - val_loss: 1.0137 - val_accuracy: 0.6653\n","Epoch 22/30\n","1302/1302 [==============================] - 89s 68ms/step - loss: 0.8195 - accuracy: 0.7452 - val_loss: 1.0220 - val_accuracy: 0.6628\n","Epoch 23/30\n","1302/1302 [==============================] - 90s 69ms/step - loss: 0.8122 - accuracy: 0.7474 - val_loss: 1.0280 - val_accuracy: 0.6620\n","Epoch 24/30\n","1302/1302 [==============================] - 89s 68ms/step - loss: 0.8061 - accuracy: 0.7505 - val_loss: 1.0394 - val_accuracy: 0.6605\n","Epoch 25/30\n","1302/1302 [==============================] - 90s 69ms/step - loss: 0.7994 - accuracy: 0.7524 - val_loss: 1.0308 - val_accuracy: 0.6635\n","Epoch 26/30\n","1302/1302 [==============================] - 91s 70ms/step - loss: 0.7933 - accuracy: 0.7549 - val_loss: 1.0413 - val_accuracy: 0.6618\n","Epoch 27/30\n","1302/1302 [==============================] - 91s 70ms/step - loss: 0.7876 - accuracy: 0.7575 - val_loss: 1.0514 - val_accuracy: 0.6616\n","Epoch 28/30\n","1302/1302 [==============================] - 91s 70ms/step - loss: 0.7822 - accuracy: 0.7591 - val_loss: 1.0530 - val_accuracy: 0.6589\n","Epoch 29/30\n","1302/1302 [==============================] - 89s 68ms/step - loss: 0.7762 - accuracy: 0.7621 - val_loss: 1.0581 - val_accuracy: 0.6584\n","Epoch 30/30\n","1302/1302 [==============================] - 89s 68ms/step - loss: 0.7699 - accuracy: 0.7641 - val_loss: 1.0607 - val_accuracy: 0.6598\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fbc9a37f0a0>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["import numpy as np\n","spa_vocab = target_vectorization.get_vocabulary()\n","spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n","max_decoded_sentence_length = 20"],"metadata":{"id":"Fq_i5dofK-pw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def decode_sequence(input_sentence):\n","  tokenized_input_sentence = source_vectorization([input_sentence])\n","  decoded_sentence = \"[start]\"\n","  for i in range(max_decoded_sentence_length):\n","    tokenized_target_sentence = target_vectorization([decoded_sentence])[:, :-1]\n","    predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n","    sampled_token_index = np.argmax(predictions[0, i, :])\n","    sampled_token = spa_index_lookup[sampled_token_index]\n","    decoded_sentence += \" \" + sampled_token\n","    if sampled_token == \"[end]\":\n","      break\n","  return decoded_sentence"],"metadata":{"id":"yIOXBvtqLFjZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_eng_texts = [pair[0] for pair in test_pairs]\n","for _ in range(20):\n","  input_sentence = random.choice(test_eng_texts)\n","  print(\"-\")\n","  print(input_sentence)\n","  print(decode_sequence(input_sentence))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H68edXhuLKl3","executionInfo":{"status":"ok","timestamp":1670431353550,"user_tz":-60,"elapsed":6501,"user":{"displayName":"Zakaria Ybeggazene","userId":"17723444071190952793"}},"outputId":"9b4b1c1b-1a85-4997-e8a1-a29ab8e4b830"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-\n","I had to postpone my appointment.\n","[start] tenía que poner mi cita [end]\n","-\n","Smell this.\n","[start] [UNK] esto [end]\n","-\n","I didn't do anything.\n","[start] no hice nada [end]\n","-\n","He's always asking silly questions.\n","[start] siempre está pasando estúpido [end]\n","-\n","I thought you'd be thrilled.\n","[start] pensé que te [UNK] [end]\n","-\n","I don't feel like sitting down.\n","[start] no tengo ganas de [UNK] [end]\n","-\n","The company laid off five people.\n","[start] la compañía cayó a cinco personas [end]\n","-\n","I love talking to you.\n","[start] me encanta hablar con usted [end]\n","-\n","Do you want to sit somewhere else?\n","[start] quieres estar en otro lugar [end]\n","-\n","Tom and Mary kissed passionately.\n","[start] tom y mary se [UNK] de los los los los los los los los los los los que se [UNK]\n","-\n","Tickets are valid for just two days, including the day they are purchased on.\n","[start] las medicina son [UNK] por dos días más que son ellos en los [UNK] que están en [UNK] [end]\n","-\n","Who told you about this?\n","[start] quién te dijo sobre esto [end]\n","-\n","He goes running every morning.\n","[start] Él sale a jugar cada mañana [end]\n","-\n","He started learning English at the age of eleven.\n","[start] Él terminó aprender inglés a los seis años [end]\n","-\n","Try to keep from crying.\n","[start] intenta ayudar a llorar [end]\n","-\n","Did you call me last night?\n","[start] me has llamado anoche [end]\n","-\n","Singing is my passion.\n","[start] cantando es mi de la de la que él [UNK] [end]\n","-\n","The students are making good progress in English.\n","[start] los estudiantes están haciendo un buen inglés [end]\n","-\n","Where's the toothpaste?\n","[start] dónde está el dientes de [UNK] [end]\n","-\n","The house is made of stone.\n","[start] la casa está hecho de piedra [end]\n"]}]}]}